{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from keras import backend as K\n",
    "# if K.backend()=='tensorflow':\n",
    "#     K.set_image_dim_ordering(\"th\")\n",
    " \n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    " \n",
    "batch_size = 32 \n",
    "# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    " \n",
    "num_classes = 10 #\n",
    "epochs = 40 # repeat 20 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,3))\n",
    "# for i in range(num_classes):\n",
    "#     ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "#     idx = np.where(y_train[:]==i)[0]\n",
    "#     features_idx = x_train[idx,::]\n",
    "#     img_num = np.random.randint(features_idx.shape[0])\n",
    "#     im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
    "#     plt.imshow(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train  /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_noise = []\n",
    "import cv2\n",
    "for i in range(len(x_train)):\n",
    "    blur = cv2.GaussianBlur(x_train[i], (5, 5), 0)\n",
    "    no_noise.append(blur)\n",
    "len(no_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             rotation_range=30,\n",
    "#             zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "it = datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-8574978d31ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "datagen.flow(x_train, y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = np.array(no_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 13, 13, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 88,282\n",
      "Trainable params: 88,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 1.6671 - accuracy: 0.3926 - val_loss: 1.5359 - val_accuracy: 0.4579\n",
      "Epoch 2/40\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 1.4144 - accuracy: 0.4943 - val_loss: 1.4972 - val_accuracy: 0.4741\n",
      "Epoch 3/40\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 1.3204 - accuracy: 0.5248 - val_loss: 1.3589 - val_accuracy: 0.5211\n",
      "Epoch 4/40\n",
      "50000/50000 [==============================] - 28s 558us/step - loss: 1.2428 - accuracy: 0.5555 - val_loss: 1.3865 - val_accuracy: 0.5132\n",
      "Epoch 5/40\n",
      "50000/50000 [==============================] - 27s 540us/step - loss: 1.1959 - accuracy: 0.5734 - val_loss: 1.3644 - val_accuracy: 0.5361\n",
      "Epoch 6/40\n",
      "50000/50000 [==============================] - 26s 525us/step - loss: 1.1502 - accuracy: 0.5909 - val_loss: 1.2772 - val_accuracy: 0.5687\n",
      "Epoch 7/40\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 1.1117 - accuracy: 0.6062 - val_loss: 1.3702 - val_accuracy: 0.5518\n",
      "Epoch 8/40\n",
      "50000/50000 [==============================] - 27s 536us/step - loss: 1.0836 - accuracy: 0.6174 - val_loss: 1.3891 - val_accuracy: 0.5409\n",
      "Epoch 9/40\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 1.0518 - accuracy: 0.6261 - val_loss: 1.4160 - val_accuracy: 0.5412\n",
      "Epoch 10/40\n",
      "50000/50000 [==============================] - 27s 546us/step - loss: 1.0268 - accuracy: 0.6360 - val_loss: 1.3918 - val_accuracy: 0.5563\n",
      "Epoch 11/40\n",
      "50000/50000 [==============================] - 31s 628us/step - loss: 1.0007 - accuracy: 0.6446 - val_loss: 1.4299 - val_accuracy: 0.5586\n",
      "Epoch 12/40\n",
      "50000/50000 [==============================] - 29s 586us/step - loss: 0.9795 - accuracy: 0.6524 - val_loss: 1.4049 - val_accuracy: 0.5693\n",
      "Epoch 13/40\n",
      "50000/50000 [==============================] - 28s 551us/step - loss: 0.9628 - accuracy: 0.6557 - val_loss: 1.4612 - val_accuracy: 0.5506\n",
      "Epoch 14/40\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.9441 - accuracy: 0.6651 - val_loss: 1.3610 - val_accuracy: 0.5674\n",
      "Epoch 15/40\n",
      "50000/50000 [==============================] - 27s 550us/step - loss: 0.9271 - accuracy: 0.6687 - val_loss: 1.3717 - val_accuracy: 0.5749\n",
      "Epoch 16/40\n",
      "50000/50000 [==============================] - 30s 592us/step - loss: 0.9078 - accuracy: 0.6773 - val_loss: 1.4061 - val_accuracy: 0.5797\n",
      "Epoch 17/40\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 0.9020 - accuracy: 0.6794 - val_loss: 1.4901 - val_accuracy: 0.5659\n",
      "Epoch 18/40\n",
      "50000/50000 [==============================] - 29s 570us/step - loss: 0.8895 - accuracy: 0.6818 - val_loss: 1.4609 - val_accuracy: 0.5740\n",
      "Epoch 19/40\n",
      "50000/50000 [==============================] - 26s 518us/step - loss: 0.8793 - accuracy: 0.6892 - val_loss: 1.5025 - val_accuracy: 0.5648\n",
      "Epoch 20/40\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 0.8696 - accuracy: 0.6909 - val_loss: 1.5806 - val_accuracy: 0.5461\n",
      "Epoch 21/40\n",
      "50000/50000 [==============================] - 26s 518us/step - loss: 0.8529 - accuracy: 0.6961 - val_loss: 1.4968 - val_accuracy: 0.5718\n",
      "Epoch 22/40\n",
      "50000/50000 [==============================] - 28s 563us/step - loss: 0.8419 - accuracy: 0.6999 - val_loss: 1.5883 - val_accuracy: 0.5509\n",
      "Epoch 23/40\n",
      "50000/50000 [==============================] - 28s 562us/step - loss: 0.8388 - accuracy: 0.7022 - val_loss: 1.5237 - val_accuracy: 0.5703\n",
      "Epoch 24/40\n",
      "50000/50000 [==============================] - 28s 562us/step - loss: 0.8323 - accuracy: 0.7047 - val_loss: 1.5331 - val_accuracy: 0.5653\n",
      "Epoch 25/40\n",
      "50000/50000 [==============================] - 28s 557us/step - loss: 0.8219 - accuracy: 0.7049 - val_loss: 1.5252 - val_accuracy: 0.5657\n",
      "Epoch 26/40\n",
      "50000/50000 [==============================] - 29s 572us/step - loss: 0.8197 - accuracy: 0.7093 - val_loss: 1.6398 - val_accuracy: 0.5551\n",
      "Epoch 27/40\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.8090 - accuracy: 0.7119 - val_loss: 1.5751 - val_accuracy: 0.5599\n",
      "Epoch 28/40\n",
      "50000/50000 [==============================] - 27s 542us/step - loss: 0.8011 - accuracy: 0.7149 - val_loss: 1.5555 - val_accuracy: 0.5740\n",
      "Epoch 29/40\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 0.7920 - accuracy: 0.7196 - val_loss: 1.6220 - val_accuracy: 0.5419\n",
      "Epoch 30/40\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 0.7857 - accuracy: 0.7198 - val_loss: 1.5806 - val_accuracy: 0.5701\n",
      "Epoch 31/40\n",
      "50000/50000 [==============================] - 28s 563us/step - loss: 0.7812 - accuracy: 0.7199 - val_loss: 1.5646 - val_accuracy: 0.5670\n",
      "Epoch 32/40\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 0.7783 - accuracy: 0.7220 - val_loss: 1.5706 - val_accuracy: 0.5665\n",
      "Epoch 33/40\n",
      "50000/50000 [==============================] - 26s 526us/step - loss: 0.7652 - accuracy: 0.7276 - val_loss: 1.6557 - val_accuracy: 0.5708\n",
      "Epoch 34/40\n",
      "50000/50000 [==============================] - 27s 534us/step - loss: 0.7663 - accuracy: 0.7268 - val_loss: 1.7048 - val_accuracy: 0.5641\n",
      "Epoch 35/40\n",
      "50000/50000 [==============================] - 26s 526us/step - loss: 0.7542 - accuracy: 0.7296 - val_loss: 1.7346 - val_accuracy: 0.5625\n",
      "Epoch 36/40\n",
      "50000/50000 [==============================] - 27s 534us/step - loss: 0.7569 - accuracy: 0.7292 - val_loss: 1.6079 - val_accuracy: 0.5796\n",
      "Epoch 37/40\n",
      "50000/50000 [==============================] - 26s 518us/step - loss: 0.7511 - accuracy: 0.7302 - val_loss: 1.8332 - val_accuracy: 0.5520\n",
      "Epoch 38/40\n",
      "50000/50000 [==============================] - 27s 532us/step - loss: 0.7429 - accuracy: 0.7341 - val_loss: 1.8743 - val_accuracy: 0.5448\n",
      "Epoch 39/40\n",
      "50000/50000 [==============================] - 26s 510us/step - loss: 0.7437 - accuracy: 0.7327 - val_loss: 1.7540 - val_accuracy: 0.5700\n",
      "Epoch 40/40\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.7387 - accuracy: 0.7370 - val_loss: 1.6513 - val_accuracy: 0.5770\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(32,(3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(64, (3,3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(num_classes))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     sgd = SGD(lr = 0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D())\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Train model\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "cnn_n = base_model()\n",
    "cnn_n.summary()\n",
    "\n",
    "# Fit model\n",
    "\n",
    "cnn = cnn_n.fit(x_train1, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)\n",
    "# history = cnn_n.fit_generator(\n",
    "# #       it.flow(x_train,y_train),\n",
    "#     datagen.flow(x_train, y_train, batch_size=32),\n",
    "#       steps_per_epoch=len(x_train) / 32 ,\n",
    "#       epochs=30,\n",
    "#       validation_data=(x_test,y_test),\n",
    "# #       validation_steps=len(x_train) / 32,\n",
    "# verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
